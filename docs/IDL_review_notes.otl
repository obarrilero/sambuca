References
	Mapping IDL to Python
		http://www.scicoder.org/mapping-idl-to-python/
		: Not always the best reference. For example, for Amoeba minimisation
		: it points to a bespoke python script rather than the Scipy
		: implementation

Initial questions
	Data
		input formats?
			ESRI
			ENVI HDR
			Other raster formats (GeoTIFF etc)
			Custom
				binary?
					watch for endianess
		output formats?
		What data structures are used?
			What is the best way to translate them to numpy?
		Does the code need to explicitly deal with spatial aspects of the data (projections etc)?
			or does it just see an array of pixels
		How can I breakdown the large global data structure to be more modular?
			Identify coherent subsets of data required by the processing modules
	What are the plotting requirements?
		Should the plots be generated by Python at all?
			: Can I just write out to HDF using an appropriate convention(CF-1.2?),
			: and then use standard tools (ESRI, ENVI, Panoply) to visualise the
			: data?
		If plotting from Python, what library will I need?
			Matplotlib, Basemap, veusz...
	Processing:
		numpy, scipy
		does single or double precision matter?
	What IDL-specific capabilities are used that might be hard to substitute in Python?

sambuca_2009.pro
	function machine_name
		:Straightforward. On windows it searches the environment and returns 
		:the machine name. On linux it returns "unix" but it could easily
		:check the value of $HOSTNAME.
	function DO_whole_guacamole
		purpose
			: Contrary to the name, it doesn't "do" or execute anything. It just
			: appears to construct the whole_guacamole structure
		arguments
			pstate
			zzzz
				:z value. What is the z value in this context?
		common
			SAMBUCA_share
				:Where is the common SAMBUCA_share structure defined?
				:It looks like it is setup in sambuca_2009_wid.pro, function SAMBUCA_2009_pre
		whole_guacamole is a structure of arrays
			What is the purpose of each array?
				name
				value
				pupper
					:an upper limit to something
				plower
					:a lower limit to something
				start
				scale
					:defines the initial step size used by the amoeba
					:minimisation routine.
			Number of parameters is hard-coded. 
				Could be data driven?
			Ask the team for explanation of each element set
				what is 'CHL', 'CDOM' etc
	procedure restore_envi_library
		purpose
			Searches for an ENVI file by name,
			Reads metadata for the file
			Puts the metadata into a structure used by Sambuca
				: lib parameter
		The Python GDAL library reads ENVI rasters. Will it also let me query the metadata?
	function SAMBUCA_SA_V12_fwdVB
		purpose
			: From the name, I think it represents version 12 of the forward model
		arguments/variables
			||variables|description|vector/scalar/structure|
			|ZZ|looks like a big collection of inputs|vector?|
			|input_params.theta_air||scalar|
			|input_params.lambda0cdom||scalar|
			|input_spectra.wl||vector|
			|input_spectra.awater|||
			|input_spectra.bbwater|||
			|input_spectra.acdom_star|abs. coeff for CDOM, where a_cdom_550 = 1||
			|input_spectra.atr_star|abs coeff og tripton, where a_tr_550 = sample dependent||
			|input_spectra.bbph_star|backscatter due to phytoplankton||
			|input_spectra.bbtr_star|backscatter due to tripton||
			|input_spectra.substrateR|||
			|thetaw|subsurface solar zenith angle in radians||
			|thetao|subsurface viewing angle in radians||
			|a_cdom_lambda0cdom||scalar|
			|n_wls|number of elements in wav (input_spectra.wl)||
			|CHL|chlorophyl concentration||
			|CDOM|cdom concentration||
			|TR|tripton concentration||
			|X_ph_lambda0x|specific backscatter of chlorophyl at lambda0x||
			|X_tr_lambda0x|specific backscatter of tripton at lambda0x||
			|Sc|cdom absorption slope||
			|Str|TR absorption slope||
			|a_tr_lambda0tr|||
			|Y|||
			|q1|||
			|q2|||
			|q3|||
			|H|||
			|Qwater|||
			|a|||
			|bb|||
			|u|||
			|kappa|||
			|DuColumn|opt. path elongation for scatterd photons from column||
			|DuBottom|opt. path elongation for scatterd photons from bottom||
			|rrsdp|remote sensing reflectance for opt[optional? optically?] deep water||
			|Kd|||
			|Kuc|||
			|Kub|||
			|rrs|||
			|closed_spectrum|||
			|closed_deep_spectrum|||
	function sub5_SAMBUCA_SA_V12
		purpose
			prepares inputs (ZZ) for the forward model
			runs the forward model
				:call to the forward model is hard-coded. Would it make sense
				:to pass the function in as an argument? This would allow
				:plugging different forward models so long as they have the
				:same interface.
			prepares the forward model outputs for input to SAMBUCA
			evaluates the error function
				:error function is hard-coded into this function. It might be
				:better to pass an error function in as an argument.
			returns error
		common
			SAMBUCA_share
		arguments
			Z:?
		variables
			||variable|description|scalar/vector/structure|
			|ZZ|forward run parameters?|float array, length 15|
			|ZZ(SAMBUCA.opti_params.Zi)=Z|Zi is a range? Appears to be setting the free parameters to be used later in Amoeba||
			|ZZ(SAMBUCA.opti_params.Fi)=SAMBUCA.opti_params.F|Fi is a range? Setting fixed parameters into ZZ||
			||||
			||||
	procedure SAMBUCA_plot_SIOP
		purpose
			:Is this an optional procedure that is only called to produce
			:a plot? Or are there side-effects on some data structures
			:(SAMBUCA_share perhaps) which mean this procedure must be called
			:as part of the core workflow?
			:If it is an optional plot function, then all is well. If it is
			:part of the core workflow, then it should be refactored into two
			:functions - an optional plot function, and the core workflow
			:component.
		common
			SAMBUCA_share
		arguments
			pstate
				:appears to be flags and other user options from the GUI
			pstate.flag.get_z
				:determines whether a z value is used (zzzz=2. passed to 
				:do_whole_guacamole)
		comments
			line 477
				:appears to be determining indicies for the fixed (Fi) and
				:free (Zi) parameters in use for the current run. Will probably 
				:need careful study to translate the intent to Python in a
				:Pythonic way.
			line 512
				:the envi_plot_data call
			line 514
				times and executes a hard-coded 50 iterations of the forward model, then prints the avg time per model run
					why 50 iterations?
					why is the returned error term thrown away?
					is this whole section just debugging code? It smells like debug code that shouldn't be there.
					:regardless, the Python code will need to deal with this
					:more gracefully
	procedure SAMBUCA_2009
		purpose
			appears to be the primary sambuca runner
			grabs some options
			reads input files
				pstate.p_input_info?
				where is the lib argument to restore_envi_library declared?
					Implicitly in restore_envi_library call?
				Are the envi libraries connected to the compressed/categorised inputs?
			opens a whole bunch of output files
			line 669: initialises debug printing
				:could I use a lightweight python logging framework?
			reads the image data
				:Python can use reader pattern to separate input formats from
				:core code. GDAL might do it, but might be better off with
				:a thin layer over the top of gdal if there is extra work to
				:do.
			loops over tiles
				but no parallel execution of tiles
					:parallelism: tiles to processes (MPI?), and pixels to
					:threads?
				each tile loop contains an inner pixel loop
					:line 734
					seems to be doing a lot of work
					line 768:
						:can else block for non-zero pixel processing be 
						:promoted by having an early-exit on zero pixels?
					line 799:
						:does the whole_guacamole structure differ per-pixel?
						:Could any of the parameter setup code be moved out of
						:the inner loop?
					line 791:
						:loops over all input substrates (per-pixel)
					searches for and records some parameter indicies
					sets up some other values
					if pixel is in z range (min, max), calls amoeba minimisation function
					line 884: checks amoeba_converged value
						:value is set inside a loop, check is outside the
						:loop. So the check only sees the value from the final
						:iteration!
					line 998: pixel loop ends
				writes out tile results
				line 1041: end of tile loop
			line 1044: appears to be writing out ENVI-specific headers for the results.
				:I would like to use a writer pattern to keep file formats
				:separate from the core code
				there are a whole bunch of option tests, followed by output for that option
					:would this work with a collection of writers? All this
					:code would then be hidden inside the writer classes, and
					:the main loop would have something like
					:"writers.writeHeaders()"
		common
			SAMBUCA_share
		

amoeba_clw7.pro
	Is the 7 a version number?
		If so, what is the history?
	Performs multidimensional minimisation of a function using the downhill simplex method
		Does not require a derivative function
	Appears to be a modified version of the IDL standard function.
		: I suspect that one modification is the splitting out of the
		: amotry_CLW2 function, and the addition of the common block, as the
		: original function block comment indicates no common blocks. Would
		: need to diff against original to check, but it probably doesn't
		: matter for the port.
		ToDo: identify whether a replacement exists in SciPy.
			Yes
				: downhill simplex (Nelder-Mead/Amoeba) is available as an option
				: in minimise using method='Nelder-Mead'
				: http://stackoverflow.com/questions/9613381/python-function-minimisation-without-derivative
				: http://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html?highlight=nelder
			Does the IDL function do anything strange that will prevent use of the SciPy version?

IDL quirks to watch
	arrays
		IDL arrays are row-major, but differ from standard matrix notation by using (column, row) rather than (row, column)
		: so indexing looks like column-major but it's not. Rationale is that
		: memory layout for 2D images matches the data access ordering of device
		: scanlines
			will just have to watch indexing orders in Python
		array subscripts are 0-based (yeay)
		implicit array operations
		default is to use [] for array subscripts, but () is legal (and confusing since it looks like a function call)
	Common Blocks
		Global data dressed up so it doesn't look like a bad idea, but it is.
		it could be addressed by objects: common blocks become object data, functions and procedures become methods
	Functions & Procedures
		It looks like procedures don't have a return value, but functions do.
		Side effects!! Both functions and procedures routinely make permanent changes to input arguments
		Keyword arguments
			names can be shortened, so watch for errors caused by similar names
	dynamic typing
		values have a hard type (string, float, double etc)
		references can point to any type
		: So a='a' followed by a=3 does not change a string to an int. It just
		: changes the data type referenced by a
	data types
		default int is only 16 bits. Need long for 32 bits
		float (32 bits) and double (64 bits) make sense

Sambuca common features
	tight binding to GUI
		:a number of Sambuca functions directly trigger an IDL message box. In
		:python it will be better to throw an exception. This will keep
		:a clean separation between the core code and any GUI that may or may
		:not be layered over the top.
